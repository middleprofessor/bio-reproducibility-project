---
title: 'Data from: Density triggers maternal hormones that increase adaptive offspring growth in a wild mammal'
author: Jeff Walker
date: '2018-04-30'
slug: data-from-density-triggers-maternal-hormones-that-increase-adaptive-offspring-growth-in-a-wild-mammal
categories: []
tags:
  - ecology
  - physiology
  - reproducible
  - red flag
  - linear mixed model
  - experiment
output:
  blogdown::html_page:
    toc: true
---
```{r prep, echo=FALSE, message=FALSE}
library(ggplot2)
library(data.table)
library(lme4)
library(lmerTest)

base_path <- "../" #knitr
#base_path <- "content/"  # console
folder <- '2018-04-30-data-from-density-triggers-maternal-hormones-that-increase-adaptive-offspring-growth-in-a-wild-mammal'
```

# Sources
Dantzer, B., Newman, A.E., Boonstra, R., Palme, R., Boutin, S., Humphries, M.M. and McAdam, A.G., 2013. Density triggers maternal hormones that increase adaptive offspring growth in a wild mammal. Science, p.1235765. [Google Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C20&q=Density+triggers+maternal+hormones+that+increase+adaptive+offspring+growth+in+a+wild+mammal&btnG=){target="_blank"}

Dantzer B, Newman AEM, Boonstra R, Palme R, Boutin S, Humphries MM, McAdam AG (2013) Data from: Density triggers maternal hormones that increase adaptive offspring growth in a wild mammal. Dryad Digital Repository. [https://doi.org/10.5061/dryad.b3h4q](https://doi.org/10.5061/dryad.b3h4q){target="_blank"}

# Background
The study showed that North American red squirrel (*Tamiasciurus hudsonicus*) mothers from Yukon, Alaska produce faster growing pups in years with increased squirrel density. The researchers showed this mechanism is through increased plasma levels of the stress hormone cortisol, as measured by fecal cortisol metabolites ($FCM$) Remarkably, the researchers even showed that perceived (but not actual) density results in increased $FCM$ and faster growing pups.

# Effect of spruce cone availability on local density (Fig. 1B)
## Reproducibility
```{r Fig1B}
# https://datadryad.org/resource/doi:10.5061/dryad.b3h4q
# data for Fig 1B/Table Sxxx
# 
fn <- 'Spruce cone and density data.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
dt.fig_1B <- data.table(read.table(file_path, sep=',', header=TRUE))
fit1B <- lm(Raw.Spring.Squirrel.Density ~ Previous.Year.Cones + Study.Area, data=dt.fig_1B[Treatment=='Control'])
coefficients(summary(fit1B))
fit1B <- lmer(Raw.Spring.Squirrel.Density ~ Previous.Year.Cones + (1|Study.Area), data=dt.fig_1B[Treatment=='Control'])
coefficients(summary(fit1B))
fit1B <- lmer(Raw.Spring.Squirrel.Density ~ Treatment*Previous.Year.Cones + (1|Study.Area), data=dt.fig_1B)
coefficients(summary(fit1B))

```

# Effect of Density on growth rate (Fig. 2/Table S2)
## Reproducibility
Estimate, t, SE, and t reproduce but reported p-values are < 1/2 reproduced p-value. Is difference due to something other than lmterTest? Or are one-tailed p-values being used?

```{r tableS2}
fn <- 'Table S2 - neonate mass and growth rate.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
dt.table_S2 <- data.table(read.table(file_path, sep=',', header=TRUE))
fit <- lmer(Offspring.Growth.Rate ~ Scaled.Litter.Size*Treatment + (1|Mom.Squirrel.ID), data=dt.table_S2, na.action="na.exclude")
coefficients(summary(fit))

```

## Red flags
### Growth rate is a change score and is confounding by the basline
The confounding makes no difference for these data.

```{r tableS2_baseline}
refit <- lmer(Offspring.Growth.Rate ~ Offspring.Weight.1 + Scaled.Litter.Size*Treatment + (1|Mom.Squirrel.ID), data=dt.table_S2, na.action="na.exclude")
coefficients(summary(refit))
```

### Figure 2 doesn't make sense
Fig. 2 doesn't make sense. If these are residuals from the model, there should be no Litter size or treatment (or any other) effect. I have plotted the raw growth rate against Scaled.Litter. Note the regression lines will be slightly different because they do not account for random effect of squirrel ID. Regardless, the lines are extremely close to the linear mixed modeled growth rates for each treatment at small litter size (n=2) and large litter size (n=5). This picture suggests a very different story. At best, one might say that treated growth rates are depressed, relative to control, at small litter size, and a bit elevated at large litter size. But the data are noisy, as indicated by p-values and there is a potential outlier in the control data at litter size = 2 (scaled.litter.size = -2.302608)

```{r Fig2, warning=FALSE}
# plot raw litter size
qplot(x=Raw.Litter.Size, y=Offspring.Growth.Rate, color=Treatment, data=dt.table_S2) + geom_point() + geom_smooth(method='lm')
# scaled litter size
qplot(x=Scaled.Litter.Size, y=Offspring.Growth.Rate, color=Treatment, data=dt.table_S2) + geom_point() + geom_smooth(method='lm')

# compare modeled values from model at small and large end of scaled.litter.size
# mapping litter size to scaled litter size
# 1 = -3.369161 (n=1)
# 2 = -2.302608
# 3 = -1.2360545
# 4 = -0.1695011
# 5 = 0.8970522
# 6 = 1.9636056
b <- coefficients(summary(fit))[,'Estimate']
# at litter size = 2
modeled_GR <- data.table(Treatment=c('Control','Food','Rattle'),
              Litter.eq.2=c(
              b['(Intercept)'] + b['Scaled.Litter.Size']*-2.302608,
              b['(Intercept)'] + b['TreatmentFood'] +
              (b['Scaled.Litter.Size']+b['Scaled.Litter.Size:TreatmentFood'])*-2.302608,
              b['(Intercept)'] + b['TreatmentRattle'] +
              (b['Scaled.Litter.Size']+b['Scaled.Litter.Size:TreatmentRattle'])*-2.302608
              ),
              Litter.eq.5=c(
               b['(Intercept)'] + b['Scaled.Litter.Size']*0.8970522,
              b['(Intercept)'] + b['TreatmentFood'] +
              (b['Scaled.Litter.Size']+b['Scaled.Litter.Size:TreatmentFood'])*0.8970522,
              b['(Intercept)'] + b['TreatmentRattle'] +
              (b['Scaled.Litter.Size']+b['Scaled.Litter.Size:TreatmentRattle'])*0.8970522
              ))
modeled_GR # compare to plot

# compare to linear model
# fit_lm <- lm(Offspring.Growth.Rate ~ Scaled.Litter.Size*Treatment, data=dt.table_S2, na.action="na.exclude")
# coefficients(summary(fit_lm))
# so outling point is okay
```


# Effect of Density on fecal cortisol metabolites (Fig. 3/Table S4)
## Reproducibility
To begin to investigate how squirrel density during pregnancy could control the future growth rate of pups, Dantzer et al measured the relationship between local squirrel density (the variable $Density$) and the amount of fecal cortisol metabolites from pregnant mothers (the variable $FCM$). Cortisol is a hormone that is secreted as part of stress response. Dantzer et al were interested in cortisol because it is known that, in mammals, blood cortisol levels in pregnant mothers have numerous effects on offspring long past birth. If increased squirrel density causes increased blood cortisol levels, then we would expect to find a positive relationship between $Density$ and $FCM$.

Dantzer et al analyzed effect of $Density$ on $FCM$ with three different analyses.

1. $Density$ as continuous $X$. Modeled with a linear mixed model. The data are from individual, tagged squirrels from different populations and different years. About 1/2 the data is from experimental populations with supplemented food (peanut butter) to increase density. The model includes days post conception as a covariate and squirrel $ID$ and $Year$ are modeled with random intercepts.

2. Density as levels of $Treatment$. The two levels are N (control) and Y (supplemental peanut butter). The data are the same as in part 1 so this is not a replication or alternative probing.

3. Density as perceived density $Treatment$ with two levels: control (including both no manipulation and chickadee call manipulation) and rattle (rattle sound mimicking neighbor squirrels)

```{r repS4part1}
# Dantzer, B., Newman, A.E., Boonstra, R., Palme, R., Boutin, S., Humphries, M.M. and McAdam, A.G., 2013. Density triggers maternal hormones that increase adaptive offspring growth in a wild mammal. Science, p.1235765.
# https://datadryad.org/resource/doi:10.5061/dryad.b3h4q
# data for Fig 3A/Table S4
# fn <- 'Spruce cone and density data.csv'
fn <- 'FCM data dryad.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
fcmA <- data.table(read.table(file_path, sep=',', header=TRUE))
# replace labels with more codeable names. Separate to insure match
setnames(fcmA, old=c('Squirrel.ID'), new=c('ID'))
setnames(fcmA, old=c('Year.Sample.Collected'), new=c('Year'))
setnames(fcmA, old=c('FCM.ng.g.dry'), new=c('FCM'))
setnames(fcmA, old=c('Food.Add.Grid'), new=c('Treatment'))
setnames(fcmA, old=c('Raw.Squirrel.Density'), new=c('Density'))
setnames(fcmA, old=c('scaled.days.postconception'), new=c('Days_pc'))
fcmA[,Treatment:=factor(Treatment)]

#lmm - replicates! but weird as uses experimental data in this without Treatment as a variable
fit_A <- lmer(log(FCM) ~ Days_pc + Density + (1|Year) + (1|ID), data=fcmA, na.action="na.exclude")
table_part1 <- coefficients(summary(fit_A))
```

Part II
```{r repS4part2}
# categorical model as in Table S4 and Figure 3B - replicates!
# data same as in part 1 but re-analyzed as categorical
fit_B <- lmer(log(FCM) ~ Days_pc + Treatment + (1|Year) + (1|ID), data=fcmA)
table_part2 <- coefficients(summary(fit_B))

```

Part III

```{r repS4part3, eval=TRUE}
#Table S4, figure 3C - replicates
fn <- 'Table S4 - playback FCM data.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
fcmC <- data.table(read.table(file_path, sep=',', header=TRUE))
fcmC[,Treatment:=factor(Treatment)]
setnames(fcmC, old=c('Squirrel.Taglft'), new=c('ID'))
setnames(fcmC, old=c('FCM.ng.g.dry'), new=c('FCM'))
setnames(fcmC, old=c('scaled.days.postconception'), new=c('Days_pc'))
fit_C <- lmer(log(FCM) ~ Days_pc + Treatment + (1|ID), data=fcmC)
table_part3 <- coefficients(summary(fit_C))

```

Figure S3, which is the FCM as a function of treatment level (chickadee vs. rattle) *prior* to playback
```{r repS3}
#Supplement page 7 - methods in text, page 11 - Figure S3
fn <- 'before.playback.fcm.data.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
fcmC_pre <- data.table(read.table(file_path, sep=',', header=TRUE))
setnames(fcmC_pre, old=c('Raw.FCM.ng.g.dry'), new=c('FCM'))
setnames(fcmC_pre, old=c('Squirrel.Taglft'), new=c('ID'))
setnames(fcmC_pre, old=c('Days.Post.Conception'), new=c('Days_pc'))
fcmC_pre[,Treatment:=factor(Treatment)]
# model - why interaction here but not elsewhere? Note treatment effect bigger in additive model
fit3 <- lmer(log(FCM) ~ Days_pc*Treatment + (1|ID), data=fcmC_pre)
tableS3_rep <- coefficients(summary(fit3))
# compare to (t97 = -0.93, P = 0.17) from p. 11 of supplement
qplot(x=Treatment, y=log(FCM), data=fcmC_pre) + geom_boxplot() + geom_point()
```

**Replicated results**

The effects, SE, and t replicate but the my $p$-values are twice those of the authors, who must be reporting 1-tailed (directional) tests. I don't see that they have reported that they are using 1-tailed tests. My opinion is that one-tail tests are p-hacking.

```{r TableS4rep}
table_part1
table_part2
table_part3
```

```{r TableS4_image, echo=FALSE}
fn <- 'tableS4.png'
file_path <- paste("images", folder, fn, sep="/")
image_path <- paste("../../" , file_path, sep="")
knitr::include_graphics(image_path)

```

## Red flags
### one-tailed tests
The authors reported p-values from one-tailed tests, apparently without reporting that these are one-tailed tests (at least I cannot find this with a search). As stated above, I think one-tailed tests are p-hacking -- Conclusions or a decision to publish a paper in *Science* shouldn't rest on a p-value of 0.03 or 0.06. It also assumes that effects in the opposite direction cannot exist. If one has prior information on the direction of an effect then use this in a Bayesian model.

### Forking paths
There is variation among the analyses. Sometimes $Days_{pc}$ includes a quadratic component sometimes not. Some analysis are factorial $Treatment \times Days_{pc}$ while others are additive. The analysis below shows no real consequences of obvious forking paths.

Effect of $Density$ in Table S4 part 1 is robust to forking. Effect of $Treatment$ is robust to forking.
```{r forking}
# part 1
coefficients(summary(lmer(log(FCM) ~ Days_pc + Density + (1|Year) + (1|ID), data=fcmA)))
coefficients(summary(lmer(log(FCM) ~ Days_pc*Density + (1|Year) + (1|ID), data=fcmA)))
coefficients(summary(lmer(log(FCM) ~ Days_pc + I(Days_pc^2) + Density + (1|Year) + (1|ID), data=fcmA)))

# part 2
coefficients(summary(lmer(log(FCM) ~ Days_pc + Treatment + (1|Year) + (1|ID), data=fcmA)))
coefficients(summary(lmer(log(FCM) ~ Days_pc*Treatment + (1|Year) + (1|ID), data=fcmA)))
coefficients(summary(lmer(log(FCM) ~ Days_pc + I(Days_pc^2) + Treatment + (1|Year) + (1|ID), data=fcmA)))

```

### Confounding Density and Treatment in Fig 3A,B/Table S4

```{r explorefig3a, warning=FALSE, fig.cap="Re-plot of Figure 3A. Data color coded by Treatment level"}
# residuals from Days_pc
fcmA[, FCM_residuals:=residuals(lm(log(FCM) ~ Days_pc, data=fcmA))]
qplot(x=Density, y=FCM_residuals, color=Treatment, data=fcmA) + geom_point() + geom_smooth(method='lm')

# residuals from lmm
fcmA[, FCM_p1_residuals:=residuals(fit_A)]
# qplot(x=Density, y=FCM_p1_residuals, color=Treatment, data=fcmA) + geom_point() + geom_smooth(method='lm')

```

Parts 1 and 2 are not independent tests of the hypothesis that density causes increased plasma cortisol, as these are the same data. Worse, $Treatment$ confounds part 1 and $Density$ confounds part 2. The effects of this confounding are seen with a simple scatterplot of the $FCM$ against $Density$ with points colored by $Treatment$ and separate regressions fit to each level (Figure \@ref(fig:explorefig3a)). If it were simply a density effect, the treated fit should not be elevated relative to the control data.

To unconfound these, instead of two models (parts 1 and 2), both $Density$ and $Treatment$ could be combined into the same model. (note: Does this raise colinearity issues? No the correlation is only moderate)

```{r tableS4part1Flags}
cor(fcmA$Density, as.integer(fcmA$Treatment), use='complete.obs')
fit2 <- lmer(log(FCM) ~ Days_pc + Density + Treatment + (1|Year) + (1|ID), data=fcmA)
tableS4_part1 <- coefficients(summary(fit2))
tableS4_part1
```

**Conclusion** from the red-flag analysis.

$Density$ has effect of .21 log(fcm)/squirrel-per-ha, which is 40% smaller effect than in model confounded by Treatment. Can this effect account for growth rate variation? $Treatment$ has a 50% bigger effect than $Density$ but this includes aspects of $Treatment$ that are *independent* of $Density$. The p-values for both are not strong evidence against a trivially small effect. This should be rigorously probed in follow-up experiments.

### What is effect of ignoring Chickadee manipulation in Fig 3C/Table S4
The data for Figure 3C/Table S4 part 3 has Treatment levels "Control" and "Rattle" but the Control level includes squirrels that were given a Chickadee playback. In fact, very little of the data is control. The coding of which were truly Control and which were Chickadee is in the File for Figure S3, which is the data for FCM for *pre-playback* squirrels in Chickadee and Rattle treatment levels. I used the tag data to identify the "Controls" in the Table S4 data that were actually "Chickadee".

```{r recodeTableS4Treatment}

# combine into single file with three treatment levels (control + chickadee + rattle) and two time levels (before, after)
# note that days_pc is scaled in fcmC but raw in fcmC_pre
fcmC_post <- copy(fcmC)
fcmC_pre[, Days_pc:=scale(Days_pc)]
temp <- match(fcmC_post$ID, fcmC_pre$ID)
fcmC_post[, Treatment_chick:=fcmC_pre[temp, Treatment]]
fcmC_post[, Treatment_chick:=factor(ifelse(is.na(Treatment_chick), as.character(Treatment), as.character(Treatment_chick)), c('Control', 'Chickadee', 'Rattle'))]

```

#### red flag: ID F3007/F3008 is coded as "Control" in the playback (Table S4) data but as "Rattle" in the pre-playback data (Figure S3)
I don't know the correct code but if re-coded as in the pre-playback file, there is a 10% reduction in the estimated effect and the p-value is even less evidence against a trivially small effect.

```{r TableS4C_redflag1}
# RED FLAG - ID F3007/F3008 is coded as "Control" in the playback data but as "Rattle" in the pre-playback data
fcmC_post[ID=='F3007']
fcmC_pre[ID=='F3007']

# original coefficient table that replicates
coefficients(summary(lmer(log(FCM) ~ Days_pc + Treatment + (1|ID), data=fcmC_post)))

# recoded coefficient table with smaller effect
fcmC_post[, Treatment_F3007:=Treatment]
fcmC_post[ID=='F3007', Treatment_F3007:='Rattle']
coefficients(summary(lmer(log(FCM) ~ Days_pc + Treatment_F3007 + (1|ID), data=fcmC_post)))

```

#### Red Flag: The plot and table show that the effect of playback on $FCM$ seems to be a manipulation factor that is not specific to Rattle

```{r TableS4C_redflag2}
fcmC_post[, logFCM_residuals:=residuals(lm(log(FCM)~Days_pc, data=fcmC_post), na.action="na.exclude")]
qplot(x=Treatment_chick, y=logFCM_residuals, data=fcmC_post) + geom_point()
qplot(x=Treatment_chick, y=logFCM_residuals, data=fcmC_post) + geom_point() + geom_point(data=fcmC_post[ID=="F3007"], color='red')

fit3 <- lmer(log(FCM) ~ Days_pc + Treatment_chick + (1|ID), data=fcmC_post)
tableS4_part3_rf <- coefficients(summary(fit3))
tableS4_part3_rf

```

### Justification for using chickadee playback as "Control"
From the supplement "We combined females exposed to chickadee playbacks and those exposed to no playbacks from two control study areas because the chickadee playbacks did not affect FCM concentrations (LMM containing treatment, days post-conception, and days post- conception2 as fixed effect terms: t144 = -1.03, P = 0.15)."

Is this the chickadees that are "control" from the playback vs. control from TableS4 part1/2? No. I cannot recover this at all.

```{r mysteryStatistic, eval=TRUE}
dt1 <- data.table(fcmA[Treatment=='N', .SD, .SDcols=c('ID', 'FCM', 'Days_pc')])
dt2 <- data.table(fcmC_post[Treatment_chick=='Chickadee', .SD, .SDcols=c('ID', 'FCM', 'Days_pc')])
dt <- rbind(data.table(dt1, Treatment='Control'), data.table(dt2, Treatment='Chickadee'))
dt[, FCM_residual:=residuals(lm(FCM~Days_pc, data=dt))]
qplot(x=Treatment, y=FCM_residual, data=dt) + geom_point()
coefficients(summary(lm(FCM ~ Days_pc + Treatment, data=dt)))
```

### Summary of Red Flags for Figure 3/Table S4
1. The results for Figure 3A,B/Table S4 parts 1 and 2 are confounded and a re-analysis adjusting for confounding finds that much of the "difference" is due to Treatment effects that are independent of Density.
2. The results for Figure 3C/Table S4 part 3 have a coding error. I don't know the correct code. If re-coded using pre-playback codes, then effect of Rattle playback is smaller.
3. The result in Figure 3C/Table S4 part 3 masks a chickadee treatment level. A re-analysis with this coded as a distinct level indicates that the effect is common for both treatment manipulations and increased FCM is probably due to manipulation rather than "perception of density."

# Effect of FCM on offspring growth rate (Table S5)
## Reproducibility

Estimate, SE, and t reproduce but p-values are 1/2 the published p-values or slightly smaller for FCM. The exception for reproducing is the SE for FCM, the published is 0.005, here is 0.006

```{r TableS5}
fn <- 'Table S5 Results.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
dt.table_S5 <- data.table(read.table(file_path, sep=',', header=TRUE))
fit <- lmer(Offspring.Growth.Rate ~ Previous.Year.Cones + Current.Year.Cones + scaled.parturition.date + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")
coefficients(summary(fit)) # what is "corrected about FCM?"
```

```{r TableS5_image, echo=FALSE}
fn <- 'TableS5.png'
file_path <- paste("images", folder, fn, sep="/")
image_path <- paste("../../" , file_path, sep="")
knitr::include_graphics(image_path)
```

## Explore

```{r TableS5_Explore, fig.cap="Effect of FCM on Growth Rate"}
# simple plot
qplot(x=Corrected.FCM.ng.g.dry, y=Offspring.Growth.Rate, data=dt.table_S5) +
  geom_point() + geom_smooth(method='lm')

# refit without FCM to replot with FCM as only affect
refit <- lmer(Offspring.Growth.Rate ~ Previous.Year.Cones + Current.Year.Cones + scaled.parturition.date + scaled.litter.size + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")
dt.table_S5[, GR_residual:=residuals(refit)]
qplot(x=Corrected.FCM.ng.g.dry, y=GR_residual, data=dt.table_S5) +
  geom_point() + geom_smooth(method='lm')
# plot shows lots of noise but also interesting distribution of residuals. I would think resampling would not generate a p near 0.05. Look at CI of FCM in Table S5 - this suggests nothing is going on and p-value is biased
```

Simple Bootstrap of the fit

```{r TableS5_bootstrap, eval=FALSE}
n <- nrow(dt.table_S5)
inc <- 1:n # first sample is the original
niter <- 100
xcols <- c('Previous.Year.Cones', 'Current.Year.Cones', 'scaled.parturition.date', 'scaled.litter.size', 'Corrected.FCM.ng.g.dry')
b_mat <- matrix(NA, nrow=niter, ncol=length(xcols))
colnames(b_mat) <- xcols
for(iter in 1:niter){
  refit <- lmer(Offspring.Growth.Rate ~ Previous.Year.Cones + Current.Year.Cones + scaled.parturition.date + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5[inc,], na.action="na.exclude")
  b_mat[iter,] <- coefficients(summary(refit))[xcols,'Estimate'] 
  inc <- sample(1:n, replace=TRUE)
}
apply(b_mat, 2, quantile, c(0.025, 0.975))
```

I don't need a big bootstrap to see that my bootstrap CIs are consistent with the p-values but not consistent with published CIs. But the published CIs do not even cover the estimates for Current.Year.Cones, scaled.parturition.date, and scaled.litter.size.

From the lme4 documentation - "the new version of lme4 does not provide an mcmcsamp (post-hoc MCMC sampling) method, because this was deemed to be unreliable"

The effect size relative to noise looks very small...here are absolute effect sizes
```{r TableS5_effect}
fit <- lmer(Offspring.Growth.Rate ~ Previous.Year.Cones + Current.Year.Cones + scaled.parturition.date + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")
b <- coefficients(summary(fit))[,'Estimate']
# b*3 is the difference in growth rate between low FCM and high FCM. Rate is per days. Rate is measured as difference 25 days apart, so the added growth to difference in rate is:
added_Growth <- b['Corrected.FCM.ng.g.dry']*3*25
# growth is in dt.table_S2 
# Growth in the control group over 25 days is
growth <- dt.table_S2[Treatment=='Control', .(growth=mean(Offspring.Weight.2 - Offspring.Weight.1, na.rm=TRUE)), by=.(Raw.Litter.Size)]
growth[, augmented:=growth+added_Growth]
growth[, percent_augmented:=added_Growth/growth*100]

final_weight <- dt.table_S2[Treatment=='Control', .(weight=mean(Offspring.Weight.2, na.rm=TRUE)), by=.(Raw.Litter.Size)]
final_weight[, augmented:=weight+added_Growth]
final_weight[, percent_augmented:=added_Growth/weight*100]
```

Forking paths. Why all the covariates? This would be easier with an all subsets style alorithm but I'm just exploring.

```{r TableS5_forking}
coefficients(summary(lmer(Offspring.Growth.Rate ~ Previous.Year.Cones + Current.Year.Cones + scaled.parturition.date + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")))["Corrected.FCM.ng.g.dry",]

coefficients(summary(lmer(Offspring.Growth.Rate ~  scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")))["Corrected.FCM.ng.g.dry",]

coefficients(summary(lmer(Offspring.Growth.Rate ~ scaled.parturition.date + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")))["Corrected.FCM.ng.g.dry",]

coefficients(summary(lmer(Offspring.Growth.Rate ~ Current.Year.Cones + scaled.parturition.date + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")))["Corrected.FCM.ng.g.dry",]

coefficients(summary(lmer(Offspring.Growth.Rate ~ Current.Year.Cones + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")))["Corrected.FCM.ng.g.dry",]

coefficients(summary(lmer(Offspring.Growth.Rate ~ Previous.Year.Cones + Current.Year.Cones + scaled.litter.size + Corrected.FCM.ng.g.dry + (1|Mom.Squirrel.ID), data=dt.table_S5, na.action="na.exclude")))["Corrected.FCM.ng.g.dry",]

```

## Red flags
### small effect in obersvational design
A p-value for an observational design with multiple, somewhat arbitrary covariates, that is near 0.05 just isn't very strong evidence of anything causal. The Estimate is strongly dependent on which other covariates are in the model. Certainly there are missing confounders. See Walker 2014.

### Table S5 CIs
1. The published CIs of $Currrent_cones$, $Parturtion_date$, $Litter_size$ do not even cover the estimate. How could no-one see this?
2. The published CIs are not at all consistent with the p-value (e.g. compare for FCM)
3. I would tend to have more confidence in bootstrap CI more than p-value but then my bootstrap p-values are much more consistent with p-value. Given #1 and #2, something must be wrong with published CI.
4. From the lme4 documentation: "the new version of lme4 does not provide an mcmcsamp (post-hoc MCMC sampling) method, because this was deemed to be unreliable"
5. conclusion - this doesn't effect the paper but ... I am shocked, shocked, that the reviewers didn't catch the very glaring differences in inference between the CIs and p-values.

### How is FCM "corrected?"

These seem to be residuals, maybe from $Days_pc$?

### Evidence of FCM effect is pretty small
The effect size is very small at least relative to the noise (figure \@ref(fig:TableS5_Explore)). The absolute magnitude of added growth (from low to high end of FCM) is 0.89 grams, which adds about 1.9-3.3% to growth over 25 days (conditional on litter size and assuming the effect is independent of litter size). Or, .89 grams adds about 1.3-2.3% to final weight (again conditional on litter size). What are the ecological consequences these estimated gains?

# Effect of experiment Cortisol on growth rate (Table S6)
## Reproducibility

```{r TableS6}
fn <- 'Table S6 Results - neonate mass and growth rate.csv'
file_path <- paste(base_path, "data/", folder, "/",fn, sep="")
dt.table_S6 <- data.table(read.table(file_path, sep=',', header=TRUE))

# omitting rows with NA in growth rate
inc <- which(!is.na(dt.table_S6[, Offspring.Growth.Rate]))
dt.table_S6 <- dt.table_S6[inc, ]

fit <- lmer(Offspring.Growth.Rate ~ Scaled.Litter.Size + Treatment + (1|Litter.ID), data=dt.table_S6, na.action="na.exclude")
coefficients(summary(fit)) # what is "corrected about FCM?"

```

## Explore

Growth rate is a change score and the treatment effect is confounded by baseline
```{r TableS6_baseline}
# baseline covariate 
refit <- lmer(Offspring.Growth.Rate ~ Offspring.Weight.1 + Scaled.Litter.Size + Treatment + (1|Litter.ID), data=dt.table_S6, na.action="na.exclude")
coefficients(summary(refit)) # what is "corrected about FCM?"
```

The above is interesting because adding the baseline covariate does almost nothing to the estimate but radically changes the df.

```{r TableS6_baseline_plot}
qplot(x=Treatment, y=Offspring.Weight.1, data=dt.table_S6) +
  geom_point()
coefficients(summary(lmer(Offspring.Weight.1 ~ Treatment + (1|Litter.ID), data=dt.table_S6, na.action="na.exclude")))
```

```{r TableS6_final_plot}
qplot(x=Treatment, y=Offspring.Weight.2, data=dt.table_S6) +
  geom_point()
coefficients(summary(lmer(Offspring.Weight.2 ~ Treatment + (1|Litter.ID), data=dt.table_S6, na.action="na.exclude")))
```


## Red flags
